= Demo for Consuming from Confluent Cloud Audit Log Cluster with an AWS Lambda

This demonstrates how to consuming from Confluent Cloud Audit Log Cluster with an AWS Lambda.

DISCLAIMER: This project is for demonstration purposes only. Using the demo unmodified in production is highly discouraged. Use at your own risk.

== Building the Lambda

Go to subfolder `java` and build the the Lamda code:

```shell
./gradlew build
```

In some cases you might need to rebuild the Gradle wrapper first:

```shell
gradle wrapper
```

You should now have zip file containing the compiled Lambda in `java/app/build/distributions/app.zip`.

== Audit Log JSON Schema

For conveniance, we provide the latest version of the JSON Audig Log Schema in the `docs` folder.
The most recent version can be found here: https://docs.confluent.io/cloud/current/monitoring/audit-logging/audit-log-schema.html#audit-log-event-schema-file

== Setting up the Confluent Cloud and AWS infrastrucure

First, you need a valid audig log api key for your Confluent Cloud Organization. Please check the docs on how to get this. In subfolder `terraform/java`, copy the template `terraform.tfvars.template` to `terraform.tfvars` and add values for the audit log cluster boot strap server and the key and secret of the audit log API key.

Make sure you have logged into AWS and sufficient permission to create the required resources. You can check that you are logged in for example by calling:

```shell
aws sts get-caller-identity
```

Now set/customize some variables by copying `terraform.tfvars.template` to `terraform.tfvars`. Set at least the environment ID (in this demo we assume to use an existing environment).

If you start from scratch, initialize terraform once:

```shell
terraform init
```

Check the plan generated by terraform:

```shell
terraform plan
```

If you agree with the plan, deploy the resources (that will take some time):

```shell
terraform apply
```

== Testing the setup

In your browser, go to the AWS Lambda overview. You should see your newly created Lambda. In the `monitor` section you find a link to CloudWatch.

You can now produce sample data with the Kafka console producer. Just go to subfolder `terraform/java/generated/client-configs` and run console producer (you can find the whole command line in `client-producer.conf` if you haven't disabled this feature in the variables):

```shell
kafka-console-producer --producer.config client-producer.conf --bootstrap-server <bootstrap-server-with-port> --topic test
```

You can now paste the content of `examples/example-json-event.json` as a single line to the producer. Of course, you can customize the data.

After a while, you should see a entry in Cloud Watch.

== Temporarily disable the Lambda Trigger

For cost reasons, you can disable the trigger (which is actually the ingestion of new Audit Log Events from Confluent Cloud in this case) by setting `aws_lambda_trigger_enabled = false` in your `terraform.tfvars` file and applying the Terraform configuration afterwards. No resource will be deleted, just the trigger will be disabled.

== Wrapping things up

You can destroy all created resources including the cluster in Confluent Cloud by running the following command:

```shell
terraform destroy
```
